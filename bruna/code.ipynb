{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b93f4e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df has 10002 products\n",
      "exploded_df has 43870 products\n",
      "Vector store was reconnected! total embeddings: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel # CLIP\n",
    "#import longclip # LONG CLIP\n",
    "import torch\n",
    "\n",
    "import chromadb\n",
    "import os\n",
    "\n",
    "# Reload data\n",
    "df = pd.read_csv('/Users/brunamedeiros/Documents/GitHub/Amazon-Multimodal-Chatbot/data.csv')\n",
    "print(f\"df has {len(df)} products\")\n",
    "exploded_df = pd.read_csv('/Users/brunamedeiros/Documents/GitHub/Amazon-Multimodal-Chatbot/exploded_df.csv')\n",
    "print(f\"exploded_df has {len(exploded_df)} products\")\n",
    "\n",
    "# Reconnect to vector store\n",
    "\n",
    "# OLD\n",
    "#client = chromadb.PersistentClient(path=\"./my_vectorstore\")\n",
    "#collection = client.get_or_create_collection(name=\"amazon_products\")\n",
    "\n",
    "# client = chromadb.PersistentClient(path=\"./my_vectorstore_exploded\")\n",
    "# collection = client.get_or_create_collection(name=\"amazon_products_exploded\") \n",
    "\n",
    "client = chromadb.PersistentClient(path=\"./my_vectorstore_exploded_v2\")\n",
    "collection = client.get_or_create_collection(name=\"amazon_products_exploded_v2\") \n",
    "print(f\"Vector store was reconnected! total embeddings: {collection.count()}\\n\")\n",
    "\n",
    "# Reload CLIP model\n",
    "\n",
    "# CLIP\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# LONG CLIP\n",
    "#model, preprocess = longclip.load(\"ViT-B/32\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b953563",
   "metadata": {},
   "source": [
    "# DON'T RUN - DELETE EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b0b4aa",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "23a14d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete code inside vector store\n",
    "# all_data = collection.get()\n",
    "# if all_data['ids']:\n",
    "#     collection.delete(ids=all_data['ids'])\n",
    "#     print(f\"Deleted {len(all_data['ids'])} embeddings\")\n",
    "# else:\n",
    "#     print(\"No embeddings to delete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ba04f4",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e95ec184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get all existing text embeddings and delete them\n",
    "# all_data = collection.get()\n",
    "# text_ids = [id for id in all_data['ids'] if id.startswith('text_')]\n",
    "\n",
    "# if text_ids:\n",
    "#     collection.delete(ids=text_ids)\n",
    "#     print(f\"Deleted {len(text_ids)} existing text embeddings\")\n",
    "# else:\n",
    "#     print(\"No existing text embeddings found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6345a71b",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "- `Image` and `Variants` column, if my understanding is correct, have the identical image. The `Image` column has an actual image while the `Variants` has the link to the Amazon site for that specific product. A lot of those products are not on Amazon anymore so the link leads to an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "72b888e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Entire dataset:\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniq Id</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Asin</th>\n",
       "      <th>Category</th>\n",
       "      <th>Upc Ean Code</th>\n",
       "      <th>List Price</th>\n",
       "      <th>Selling Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Model Number</th>\n",
       "      <th>...</th>\n",
       "      <th>Product Url</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Product Details</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Color</th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>Direction To Use</th>\n",
       "      <th>Is Amazon Seller</th>\n",
       "      <th>Size Quantity Variant</th>\n",
       "      <th>Product Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4c69b61db1fc16e7013b43fc926e502d</td>\n",
       "      <td>DB Longboards CoreFlex Crossbow 41\" Bamboo Fib...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sports &amp; Outdoors | Outdoor Recreation | Skate...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$237.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.com/DB-Longboards-CoreFlex-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Uniq Id  \\\n",
       "0  4c69b61db1fc16e7013b43fc926e502d   \n",
       "\n",
       "                                        Product Name  Brand Name  Asin  \\\n",
       "0  DB Longboards CoreFlex Crossbow 41\" Bamboo Fib...         NaN   NaN   \n",
       "\n",
       "                                            Category Upc Ean Code  List Price  \\\n",
       "0  Sports & Outdoors | Outdoor Recreation | Skate...          NaN         NaN   \n",
       "\n",
       "  Selling Price  Quantity Model Number  ...  \\\n",
       "0       $237.68       NaN          NaN  ...   \n",
       "\n",
       "                                         Product Url Stock Product Details  \\\n",
       "0  https://www.amazon.com/DB-Longboards-CoreFlex-...   NaN             NaN   \n",
       "\n",
       "  Dimensions Color Ingredients Direction To Use  Is Amazon Seller  \\\n",
       "0        NaN   NaN         NaN              NaN                 Y   \n",
       "\n",
       "  Size Quantity Variant  Product Description  \n",
       "0                   NaN                  NaN  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Dataset shape:\n",
      "============================================================\n",
      "(10002, 28)\n",
      "\n",
      "\n",
      "============================================================\n",
      "Columns in the dataset:\n",
      "============================================================\n",
      "['Uniq Id', 'Product Name', 'Brand Name', 'Asin', 'Category', 'Upc Ean Code', 'List Price', 'Selling Price', 'Quantity', 'Model Number', 'About Product', 'Product Specification', 'Technical Details', 'Shipping Weight', 'Product Dimensions', 'Image', 'Variants', 'Sku', 'Product Url', 'Stock', 'Product Details', 'Dimensions', 'Color', 'Ingredients', 'Direction To Use', 'Is Amazon Seller', 'Size Quantity Variant', 'Product Description']\n",
      "\n",
      "\n",
      "============================================================\n",
      "Column types:\n",
      "============================================================\n",
      "Uniq Id                   object\n",
      "Product Name              object\n",
      "Brand Name               float64\n",
      "Asin                     float64\n",
      "Category                  object\n",
      "Upc Ean Code              object\n",
      "List Price               float64\n",
      "Selling Price             object\n",
      "Quantity                 float64\n",
      "Model Number              object\n",
      "About Product             object\n",
      "Product Specification     object\n",
      "Technical Details         object\n",
      "Shipping Weight           object\n",
      "Product Dimensions        object\n",
      "Image                     object\n",
      "Variants                  object\n",
      "Sku                      float64\n",
      "Product Url               object\n",
      "Stock                    float64\n",
      "Product Details          float64\n",
      "Dimensions               float64\n",
      "Color                    float64\n",
      "Ingredients              float64\n",
      "Direction To Use         float64\n",
      "Is Amazon Seller          object\n",
      "Size Quantity Variant    float64\n",
      "Product Description      float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "============================================================\n",
      "NaN counts:\n",
      "============================================================\n",
      "Uniq Id                      0\n",
      "Product Name                 0\n",
      "Brand Name               10002\n",
      "Asin                     10002\n",
      "Category                   830\n",
      "Upc Ean Code              9968\n",
      "List Price               10002\n",
      "Selling Price              107\n",
      "Quantity                 10002\n",
      "Model Number              1770\n",
      "About Product              273\n",
      "Product Specification     1632\n",
      "Technical Details          790\n",
      "Shipping Weight           1138\n",
      "Product Dimensions        9523\n",
      "Image                        0\n",
      "Variants                  7524\n",
      "Sku                      10002\n",
      "Product Url                  0\n",
      "Stock                    10002\n",
      "Product Details          10002\n",
      "Dimensions               10002\n",
      "Color                    10002\n",
      "Ingredients              10002\n",
      "Direction To Use         10002\n",
      "Is Amazon Seller             0\n",
      "Size Quantity Variant    10002\n",
      "Product Description      10002\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "============================================================\n",
      "Columns where all values are NaN:\n",
      "============================================================\n",
      "The columns that should be removed because all values are NaN are:\n",
      "  Brand Name\n",
      "  Asin\n",
      "  List Price\n",
      "  Quantity\n",
      "  Sku\n",
      "  Stock\n",
      "  Product Details\n",
      "  Dimensions\n",
      "  Color\n",
      "  Ingredients\n",
      "  Direction To Use\n",
      "  Size Quantity Variant\n",
      "  Product Description\n",
      "\n",
      "\n",
      "============================================================\n",
      "Columns we can work with\n",
      "============================================================\n",
      "  Uniq Id\n",
      "  Product Name\n",
      "  Category\n",
      "  Upc Ean Code\n",
      "  Selling Price\n",
      "  Model Number\n",
      "  About Product\n",
      "  Product Specification\n",
      "  Technical Details\n",
      "  Shipping Weight\n",
      "  Product Dimensions\n",
      "  Image\n",
      "  Variants\n",
      "  Product Url\n",
      "  Is Amazon Seller\n",
      "\n",
      "\n",
      "============================================================\n",
      "Final Dataset\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniq Id</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Upc Ean Code</th>\n",
       "      <th>Selling Price</th>\n",
       "      <th>Model Number</th>\n",
       "      <th>About Product</th>\n",
       "      <th>Product Specification</th>\n",
       "      <th>Technical Details</th>\n",
       "      <th>Shipping Weight</th>\n",
       "      <th>Product Dimensions</th>\n",
       "      <th>Image</th>\n",
       "      <th>Variants</th>\n",
       "      <th>Product Url</th>\n",
       "      <th>Is Amazon Seller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4c69b61db1fc16e7013b43fc926e502d</td>\n",
       "      <td>DB Longboards CoreFlex Crossbow 41\" Bamboo Fib...</td>\n",
       "      <td>Sports &amp; Outdoors | Outdoor Recreation | Skate...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$237.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Make sure this fits by entering your model num...</td>\n",
       "      <td>Shipping Weight: 10.7 pounds (View shipping ra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.7 pounds</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>https://www.amazon.com/DB-Longboards-CoreFlex-...</td>\n",
       "      <td>https://www.amazon.com/DB-Longboards-CoreFlex-...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Uniq Id  \\\n",
       "0  4c69b61db1fc16e7013b43fc926e502d   \n",
       "\n",
       "                                        Product Name  \\\n",
       "0  DB Longboards CoreFlex Crossbow 41\" Bamboo Fib...   \n",
       "\n",
       "                                            Category Upc Ean Code  \\\n",
       "0  Sports & Outdoors | Outdoor Recreation | Skate...          NaN   \n",
       "\n",
       "  Selling Price Model Number  \\\n",
       "0       $237.68          NaN   \n",
       "\n",
       "                                       About Product  \\\n",
       "0  Make sure this fits by entering your model num...   \n",
       "\n",
       "                               Product Specification Technical Details  \\\n",
       "0  Shipping Weight: 10.7 pounds (View shipping ra...               NaN   \n",
       "\n",
       "  Shipping Weight Product Dimensions  \\\n",
       "0     10.7 pounds                NaN   \n",
       "\n",
       "                                               Image  \\\n",
       "0  https://images-na.ssl-images-amazon.com/images...   \n",
       "\n",
       "                                            Variants  \\\n",
       "0  https://www.amazon.com/DB-Longboards-CoreFlex-...   \n",
       "\n",
       "                                         Product Url Is Amazon Seller  \n",
       "0  https://www.amazon.com/DB-Longboards-CoreFlex-...                Y  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Entire dataset:\")\n",
    "print(\"=\"*60)\n",
    "display(df.head(1))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Dataset shape:\")\n",
    "print(\"=\"*60)\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=\"*60)\n",
    "print(\"Columns in the dataset:\")\n",
    "print(\"=\"*60)\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=\"*60)\n",
    "print(\"Column types:\")\n",
    "print(\"=\"*60)\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=\"*60)\n",
    "print(\"NaN counts:\")\n",
    "print(\"=\"*60)\n",
    "print(df.isna().sum())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=\"*60)\n",
    "print(\"Columns where all values are NaN:\")\n",
    "print(\"=\"*60)\n",
    "print(\"The columns that should be removed because all values are NaN are:\")\n",
    "for col in df.columns:\n",
    "    if df[col].isna().sum() == df.shape[0]:\n",
    "        print(f\"  {col}\")\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=\"*60)\n",
    "print(\"Columns we can work with\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].isna().sum() != df.shape[0]:\n",
    "        print(f\"  {col}\")\n",
    "valid_cols = [col for col in df.columns if df[col].isna().sum() != df.shape[0]]\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=\"*60)\n",
    "print(\"Final Dataset\")\n",
    "print(\"=\"*60)\n",
    "display(df[valid_cols].head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa6667",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "- Strip `Uniq id` column\n",
    "    - we will use that as naming for the images and metadata for embedding. we are using .strip() to ensure no errors arise later\n",
    "- Clean URLs: ended up not using this one because checking every URL will take a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73fd2a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Uniq Id column (.strip())...\n",
      "\n",
      "0    4c69b61db1fc16e7013b43fc926e502d\n",
      "1    66d49bbed043f5be260fa9f7fbff5957\n",
      "2    2c55cae269aebf53838484b0d7dd931a\n",
      "3    18018b6bc416dab347b1b7db79994afa\n",
      "4    e04b990e95bf73bbe6a3fa09785d7cd0\n",
      "Name: Uniq Id, dtype: object\n",
      "\n",
      "Unique IDs: 10002\n",
      "Any duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning Uniq Id column (.strip())...\")\n",
    "df['Uniq Id'] = df['Uniq Id'].astype(str).str.strip()\n",
    "print()\n",
    "print(df['Uniq Id'].head())\n",
    "\n",
    "# Check for any issues\n",
    "print(f\"\\nUnique IDs: {df['Uniq Id'].nunique()}\")\n",
    "print(f\"Any duplicates: {df['Uniq Id'].duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd2a52",
   "metadata": {},
   "source": [
    "# Image Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b99622",
   "metadata": {},
   "source": [
    "Each inidivual row under `Image` column has more than one https link in it.\n",
    "\n",
    "For instance, row 1: `https://images-na.ssl-images-amazon.com/images/I/51j3fPQTQkL.jpg|https://images-na.ssl-images-amazon.com/images/I/31hKM3cSoSL.jpg|https://images-na.ssl-images-amazon.com/images/I/51WlHdwghfL.jpg|https://images-na.ssl-images-amazon.com/images/I/51FsyLRBzwL.jpg|https://images-na.ssl-images-amazon.com/images/G/01/x-locale/common/transparent-pixel.jpg`\n",
    "\n",
    "Each product has more than 1 image (showing different perspectives of product). Instead of putting them in a different column, they concatenated all URLs in the same one, dividing them by the |\n",
    "\n",
    "---\n",
    "\n",
    "The `download_first_image` does the following (**WE DIDN'T USE THIS ONE**):\n",
    "- separate the many https through the |\n",
    "- skip the transparent pixel\n",
    "    - the transparent pixel is a 1x1 pixel invisible image that Amazon uses a placeholder/tracking pixel.It looks like this `https://images-na.ssl-images-amazon.com/images/G/01/x-locale/common/transparent-pixel.jpg`. It's literally a transparent image Amazon uses for things such as web tracking, analytics, layout spacing... Therefore, we need to remove it, or else our CLIP model will try to embed an empty image).\n",
    "- Saves one image per product\n",
    "    - Majority of products (cell in `Image` column) have more than 1 image per product. We could either save 1 image per product or save all images per product. This function only saves one image per product as it is more feasible with the project deadline. It would be much more complex to handle CLIP if we were to have more than 1 image\n",
    "- Name images as the `Uniq Id`: easy to look up\n",
    "    - When we connect to Chroma and create embeddings, we can store `Uniq Id` as metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba109dd",
   "metadata": {},
   "source": [
    "`download_first_image` was the first attempt. now we changed to `get_image_embedding_from_url`. It does the same as the previous one but:\n",
    "- doesn't save images locally. It processes image and automatically embed them into chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6084ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "# processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# def get_image_embedding(image):\n",
    "#     inputs = processor(images=[image], return_tensors=\"pt\", padding=True)\n",
    "#     with torch.no_grad():\n",
    "#         embedding = model.get_image_features(**inputs)\n",
    "#     return embedding.numpy()[0]\n",
    "\n",
    "\n",
    "# # LIGHT METADATA\n",
    "# def get_image_embedding_from_url(url_string, uniq_id):\n",
    "#     \"\"\"Download image from URL and get CLIP embedding + metadata - no saving on local\"\"\"\n",
    "#     try:\n",
    "#         # split by | and get all urls\n",
    "#         urls = url_string.split('|')\n",
    "\n",
    "#         # find first URL that is not a transparent pixel\n",
    "#         for url in urls:\n",
    "#             url = url.strip()\n",
    "#             if 'transparent-pixel.jpg' not in url:\n",
    "#                 print(f\"Trying: {url}\")\n",
    "\n",
    "#                 # download to memory (not disk)\n",
    "#                 response = requests.get(url)\n",
    "#                 if response.status_code == 200:\n",
    "#                     # get image\n",
    "#                     image = Image.open(BytesIO(response.content))\n",
    "\n",
    "#                     # get CLIP embedding\n",
    "#                     embedding = get_image_embedding(image) # This just returns a numpy array - no metadata! Therefore, need to add metadata\n",
    "\n",
    "#                     # Metadata\n",
    "#                     metadata = {\n",
    "#                         \"uniq_id\": str(uniq_id),\n",
    "#                         \"type\": \"image\"\n",
    "#                     }\n",
    "\n",
    "#                     #print(f\"Got embedding for {uniq_id}\")\n",
    "#                     return embedding, metadata\n",
    "        \n",
    "#         # If no URLs worked\n",
    "#         print(f\"No valid URLs found for {uniq_id}\")\n",
    "#         return None, None\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"ERROR: {e}\")\n",
    "#         return None, None\n",
    "\n",
    "\n",
    "# # Create/connect to vector store\n",
    "# client = chromadb.PersistentClient(path=\"./my_vectorstore\")\n",
    "# collection = client.get_or_create_collection(name=\"amazon_products\")\n",
    "\n",
    "# # BATCH PROCESSING SETUP\n",
    "# BATCH_SIZE = 100  # Process 100 images at a time\n",
    "# embeddings_to_store = []\n",
    "# metadatas_to_store = []\n",
    "# ids_to_store = []\n",
    "\n",
    "    \n",
    "# # # Check/delete existing data\n",
    "# # print(f\"Current embeddings in store: {collection.count()}\\n\")\n",
    "# # if collection.count() > 0:\n",
    "# #     response = input(\"Delete existing data? (y/n): \")\n",
    "# #     if response.lower() == 'y':\n",
    "# #         all_data = collection.get()\n",
    "# #         collection.delete(ids=all_data['ids'])\n",
    "# #         print(\"Deleted existing data\\n\")\n",
    "\n",
    "\n",
    "# # EMBED \n",
    "# for i in range(len(df)):\n",
    "#     if i < len(df) and pd.notna(df['Image'].iloc[i]):\n",
    "#         uniq_id = df['Uniq Id'].iloc[i]  # Just get uniq_id\n",
    "\n",
    "#         # Skip if image was already embedded\n",
    "#         try:\n",
    "#             existing = collection.get(ids=[f\"img_{uniq_id}\"])\n",
    "#             if existing['ids']:  # If it exists, skip\n",
    "#                 print(f\"Skipping {uniq_id} - already exists\")\n",
    "#                 continue\n",
    "#         except:\n",
    "#             pass  # Doesn't exist, continue processing\n",
    "\n",
    "#         url_string = df['Image'].iloc[i]\n",
    "\n",
    "#         embedding, metadata = get_image_embedding_from_url(url_string, uniq_id)  # Pass uniq_id\n",
    "#         if embedding is not None:\n",
    "#             embeddings_to_store.append(embedding.tolist())  # Convert to list\n",
    "#             metadatas_to_store.append(metadata)\n",
    "#             ids_to_store.append(f\"img_{uniq_id}\")  # Unique ID for Chroma\n",
    "            \n",
    "#             #print(f\"Embedding shape: {embedding.shape}\")\n",
    "#             #print(\"Metadata:\", metadata)\n",
    "#             #print(\"-\" * 50)\n",
    "        \n",
    "#         # Store every BATCH_SIZE embeddings\n",
    "#         if len(embeddings_to_store) >= BATCH_SIZE:\n",
    "#             collection.add(embeddings=embeddings_to_store, metadatas=metadatas_to_store, ids=ids_to_store)\n",
    "#             print(f\"Stored batch of {len(embeddings_to_store)} embeddings\")\n",
    "#             # Clear lists for next batch\n",
    "#             embeddings_to_store = []\n",
    "#             metadatas_to_store = []\n",
    "#             ids_to_store = []\n",
    "\n",
    "# # # Store all embeddings at once\n",
    "# # if embeddings_to_store:\n",
    "# #     collection.add(\n",
    "# #         embeddings=embeddings_to_store,\n",
    "# #         metadatas=metadatas_to_store,\n",
    "# #         ids=ids_to_store\n",
    "# #     )\n",
    "# #     print(f\"Stored {len(embeddings_to_store)} embeddings in vector store!\")\n",
    "\n",
    "# # Store final batch (if any remaining)\n",
    "# if embeddings_to_store:\n",
    "#     collection.add(embeddings=embeddings_to_store, metadatas=metadatas_to_store, ids=ids_to_store)\n",
    "#     print(f\"Stored final batch of {len(embeddings_to_store)} embeddings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f0d9ac",
   "metadata": {},
   "source": [
    "### CLIP with exploded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4be467ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embedding(image):\n",
    "    inputs = processor(images=[image], return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        embedding = model.get_image_features(**inputs)\n",
    "    return embedding.numpy()[0]\n",
    "\n",
    "\n",
    "def get_image_embedding_from_single_url(url_string, uniq_id):\n",
    "    \"\"\"Download image from URL and get CLIP embedding + metadata - no saving on local\"\"\"\n",
    "    url = url_string.strip()\n",
    "    try:\n",
    "        # find first URL that is not a transparent pixel\n",
    "        if 'transparent-pixel.jpg' not in url:\n",
    "            print(f\"Trying: {url}\")\n",
    "\n",
    "            # download to memory (not disk)\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                \n",
    "                # get image\n",
    "                image = Image.open(BytesIO(response.content))\n",
    "\n",
    "                # get CLIP embedding\n",
    "                embedding = get_image_embedding(image) # This just returns a numpy array - no metadata! Therefore, need to add metadata\n",
    "\n",
    "                # Metadata\n",
    "                metadata = {\n",
    "                    \"uniq_id\": str(uniq_id),\n",
    "                    \"type\": \"image\"\n",
    "                }\n",
    "                return embedding, metadata\n",
    "        \n",
    "        # If no URLs worked\n",
    "        print(f\"No valid URLs found for {uniq_id}\")\n",
    "        return None, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# BATCH PROCESSING SETUP\n",
    "BATCH_SIZE = 100  # Process 100 images at a time\n",
    "embeddings_to_store = []\n",
    "metadatas_to_store = []\n",
    "ids_to_store = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2e3685f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TESTING IMAGE EMBEDDING\n",
      "============================================================\n",
      "------------------------------------------------------------\n",
      "Selecting 4 images linked to same product\n",
      "------------------------------------------------------------\n",
      "                            Uniq Id  \\\n",
      "0  4c69b61db1fc16e7013b43fc926e502d   \n",
      "1  4c69b61db1fc16e7013b43fc926e502d   \n",
      "2  4c69b61db1fc16e7013b43fc926e502d   \n",
      "3  4c69b61db1fc16e7013b43fc926e502d   \n",
      "\n",
      "                                               Image  \n",
      "0  https://images-na.ssl-images-amazon.com/images...  \n",
      "1  https://images-na.ssl-images-amazon.com/images...  \n",
      "2  https://images-na.ssl-images-amazon.com/images...  \n",
      "3  https://images-na.ssl-images-amazon.com/images...  \n",
      "------------------------------------------------------------\n",
      "EMBEDDING\n",
      "------------------------------------------------------------\n",
      "Trying: https://images-na.ssl-images-amazon.com/images/I/51j3fPQTQkL.jpg\n",
      "Trying: https://images-na.ssl-images-amazon.com/images/I/31hKM3cSoSL.jpg\n",
      "Trying: https://images-na.ssl-images-amazon.com/images/I/51WlHdwghfL.jpg\n",
      "Trying: https://images-na.ssl-images-amazon.com/images/I/51FsyLRBzwL.jpg\n",
      "Stored final batch of 4 embeddings\n",
      "------------------------------------------------------------\n",
      "Metadata Analysis\n",
      "------------------------------------------------------------\n",
      "Total embeddings: 4\n",
      "\n",
      "Metadata for each embedding:\n",
      "1. ID: img_4c69b61db1fc16e7013b43fc926e502d_0 | Metadata: {'uniq_id': '4c69b61db1fc16e7013b43fc926e502d', 'type': 'image'}\n",
      "2. ID: img_4c69b61db1fc16e7013b43fc926e502d_1 | Metadata: {'type': 'image', 'uniq_id': '4c69b61db1fc16e7013b43fc926e502d'}\n",
      "3. ID: img_4c69b61db1fc16e7013b43fc926e502d_2 | Metadata: {'type': 'image', 'uniq_id': '4c69b61db1fc16e7013b43fc926e502d'}\n",
      "4. ID: img_4c69b61db1fc16e7013b43fc926e502d_3 | Metadata: {'uniq_id': '4c69b61db1fc16e7013b43fc926e502d', 'type': 'image'}\n",
      "\n",
      "All uniq_ids are the same: True\n",
      "Uniq ID: 4c69b61db1fc16e7013b43fc926e502d\n",
      "Ready to run on full dataset!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TESTING IMAGE EMBEDDING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(\"Selecting 4 images linked to same product\")\n",
    "print(\"-\"*60)\n",
    "# Testing with 4 rows (those 4 images are linked to the same product)\n",
    "test_df = exploded_df[exploded_df['Uniq Id'] == '4c69b61db1fc16e7013b43fc926e502d'].head(4)\n",
    "print(test_df[['Uniq Id', 'Image']])\n",
    "\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(\"EMBEDDING\")\n",
    "print(\"-\"*60)\n",
    "#for i in range(len(exploded_df)):\n",
    "for i in range(len(test_df)):\n",
    "\n",
    "    row = exploded_df.iloc[i]\n",
    "    if pd.notna(row['Image']):\n",
    "        uniq_id = row['Uniq Id']\n",
    "        single_url = row['Image']\n",
    "\n",
    "        # create unique ChromaDB ID for each image\n",
    "        unique_chroma_id = f\"img_{uniq_id}_{i}\"\n",
    "\n",
    "\n",
    "        # Skip if image was already embedded\n",
    "        try:\n",
    "            existing = collection.get(ids=[unique_chroma_id])\n",
    "            if existing['ids']: \n",
    "                print(f\"Skipping {unique_chroma_id} - already exists\")\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        embedding, metadata = get_image_embedding_from_single_url(single_url, uniq_id)  # Just like old code\n",
    "        if embedding is not None:  # Just like old code\n",
    "            embeddings_to_store.append(embedding.tolist())\n",
    "            metadatas_to_store.append(metadata)\n",
    "            ids_to_store.append(unique_chroma_id)\n",
    "            \n",
    "            #print(f\"Embedding shape: {embedding.shape}\")\n",
    "            #print(\"Metadata:\", metadata)\n",
    "            #print(\"-\" * 50)\n",
    "        \n",
    "        # Store every BATCH_SIZE embeddings\n",
    "        if len(embeddings_to_store) >= BATCH_SIZE:\n",
    "            collection.add(embeddings=embeddings_to_store, metadatas=metadatas_to_store, ids=ids_to_store)\n",
    "            print(f\"Stored batch of {len(embeddings_to_store)} embeddings\")\n",
    "            # Clear lists for next batch\n",
    "            embeddings_to_store = []\n",
    "            metadatas_to_store = []\n",
    "            ids_to_store = []\n",
    "\n",
    "# Store final batch (if any remaining)\n",
    "if embeddings_to_store:\n",
    "    collection.add(embeddings=embeddings_to_store, metadatas=metadatas_to_store, ids=ids_to_store)\n",
    "    print(f\"Stored final batch of {len(embeddings_to_store)} embeddings\")\n",
    "\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(\"Metadata Analysis\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Showing metadata \n",
    "all_data = collection.get()\n",
    "print(f\"Total embeddings: {len(all_data['ids'])}\")\n",
    "print(\"\\nMetadata for each embedding:\")\n",
    "for i, (id, metadata) in enumerate(zip(all_data['ids'], all_data['metadatas'])):\n",
    "   print(f\"{i+1}. ID: {id} | Metadata: {metadata}\")\n",
    "\n",
    "# Check if all uniq_ids are the same\n",
    "uniq_ids = [metadata['uniq_id'] for metadata in all_data['metadatas']]\n",
    "all_same = len(set(uniq_ids)) == 1\n",
    "print(f\"\\nAll uniq_ids are the same: {all_same}\")\n",
    "if all_same:\n",
    "   print(f\"Uniq ID: {uniq_ids[0]}\") \n",
    "   print(f\"Ready to run on full dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d19d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"=\"*60)\n",
    "# print(\"FULL DATASET IMAGE EMBEDDING\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "\n",
    "# print(\"-\"*60)\n",
    "# print(\"EMBEDDING\")\n",
    "# print(\"-\"*60)\n",
    "# for i in range(len(exploded_df)):\n",
    "#     row = exploded_df.iloc[i]\n",
    "#     if pd.notna(row['Image']):\n",
    "#         uniq_id = row['Uniq Id']\n",
    "#         single_url = row['Image']\n",
    "\n",
    "#         # create unique ChromaDB ID for each image\n",
    "#         unique_chroma_id = f\"img_{uniq_id}_{i}\"\n",
    "\n",
    "\n",
    "#         # Skip if image was already embedded\n",
    "#         try:\n",
    "#             existing = collection.get(ids=[unique_chroma_id])\n",
    "#             if existing['ids']: \n",
    "#                 print(f\"Skipping {unique_chroma_id} - already exists\")\n",
    "#                 continue\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#         embedding, metadata = get_image_embedding_from_single_url(single_url, uniq_id)  # Just like old code\n",
    "#         if embedding is not None:  # Just like old code\n",
    "#             embeddings_to_store.append(embedding.tolist())\n",
    "#             metadatas_to_store.append(metadata)\n",
    "#             ids_to_store.append(unique_chroma_id)\n",
    "            \n",
    "#             #print(f\"Embedding shape: {embedding.shape}\")\n",
    "#             #print(\"Metadata:\", metadata)\n",
    "#             #print(\"-\" * 50)\n",
    "        \n",
    "#         # Store every BATCH_SIZE embeddings\n",
    "#         if len(embeddings_to_store) >= BATCH_SIZE:\n",
    "#             collection.add(embeddings=embeddings_to_store, metadatas=metadatas_to_store, ids=ids_to_store)\n",
    "#             print(f\"Stored batch of {len(embeddings_to_store)} embeddings\")\n",
    "#             # Clear lists for next batch\n",
    "#             embeddings_to_store = []\n",
    "#             metadatas_to_store = []\n",
    "#             ids_to_store = []\n",
    "\n",
    "# # Store final batch (if any remaining)\n",
    "# if embeddings_to_store:\n",
    "#     collection.add(embeddings=embeddings_to_store, metadatas=metadatas_to_store, ids=ids_to_store)\n",
    "#     print(f\"Stored final batch of {len(embeddings_to_store)} embeddings\")\n",
    "\n",
    "\n",
    "# print(\"-\"*60)\n",
    "# print(\"RESULTS\")\n",
    "# print(\"-\"*60)\n",
    "\n",
    "# all_data = collection.get()\n",
    "# print(f\"Total embeddings: {len(all_data['ids'])}\")\n",
    "\n",
    "# # Count unique uniq_ids\n",
    "# uniq_ids = [metadata['uniq_id'] for metadata in all_data['metadatas']]\n",
    "# unique_uniq_ids = set(uniq_ids)\n",
    "# print(f\"Number of different uniq_ids: {len(unique_uniq_ids)}\")\n",
    "# print(f\"Uniq IDs found: {list(unique_uniq_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "17293ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VECTOR STORE INFO:\n",
      "============================================================\n",
      "Collection name: amazon_products_exploded_v2\n",
      "Total embeddings: 4\n",
      "\n",
      "Sample IDs: ['img_4c69b61db1fc16e7013b43fc926e502d_0', 'img_4c69b61db1fc16e7013b43fc926e502d_1', 'img_4c69b61db1fc16e7013b43fc926e502d_2']\n",
      "\n",
      "Sample metadata: [{'type': 'image', 'uniq_id': '4c69b61db1fc16e7013b43fc926e502d'}, {'type': 'image', 'uniq_id': '4c69b61db1fc16e7013b43fc926e502d'}, {'uniq_id': '4c69b61db1fc16e7013b43fc926e502d', 'type': 'image'}]\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"VECTOR STORE INFO:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Collection name: {collection.name}\")\n",
    "print(f\"Total embeddings: {collection.count()}\")\n",
    "\n",
    "# Check what's inside\n",
    "if collection.count() > 0:\n",
    "    peek = collection.peek(limit=3)\n",
    "    print(f\"\\nSample IDs: {peek['ids']}\")\n",
    "    print(f\"\\nSample metadata: {peek['metadatas']}\")\n",
    "else:\n",
    "    print(\"No embeddings stored yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384dca0f",
   "metadata": {},
   "source": [
    "`Sample IDs` = Chroma's interal IDs (chroma's way of finding embedding)\n",
    "\n",
    "`Uniq ID` = our product ID in metadata\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc877df3",
   "metadata": {},
   "source": [
    "# Text Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1900c3f1",
   "metadata": {},
   "source": [
    "For text embedding, there were 2 options:\n",
    "- CLIP \n",
    "    - PROBLEM: 77 token limit\n",
    "- Another LM model like all-mini\n",
    "    - Won't align with CLIP image embeddings\n",
    "\n",
    "We opted to go with CLIP embeddings. We opted to do chunking instead of cutting down the text size to not lose valuable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb7fef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TESTING...\n",
      "============================================================\n",
      "This product is DB Longboards CoreFlex Crossbow 41\" Bamboo Fiberglass Longboard Complete. It falls under the category of Sports & Outdoors | Outdoor Recreation | Skates, Skateboards & Scooters | Skateboarding | Standard Skateboards & Longboards | Longboards. The price is $237.68. Product description: Make sure this fits by entering your model number. | RESPONSIVE FLEX: The Crossbow features a bamboo core encased in triaxial fiberglass and HD plastic for a responsive flex pattern that’s second to none. Pumping & carving have never been so satisfying! Flex 2 is recommended for people 120 to 170 pounds. | COREFLEX TECH: CoreFlex construction is water resistant, impact resistant, scratch resistant and has a flex like you won’t believe. These boards combine fiberglass, epoxy, HD plastic and bamboo to create a perfect blend of performance and strength. | INSPIRED BY THE NORTHWEST: Our founding ideal is chasing adventure & riding the best boards possible, inspired by the hills, waves, beaches & mountains all around our headquarters in the Northwest | BEST IN THE WORLD: DB was founded out of sheer love of longboarding with a mission to create the best custom longboards in the world, to do it sustainably, & to treat customers & employees like family | BEYOND COMPARE: Try our skateboards & accessories if you've tried similar products by Sector 9, Landyachtz, Arbor, Loaded, Globe, Orangatang, Hawgs, Powell-Peralta, Blood Orange, Caliber or Gullwing. Shipping weight is 10.7 pounds. This item is The product is not sold by Amazon.\n",
      "\n",
      "Creating new column...\n",
      "...new column created!\n"
     ]
    }
   ],
   "source": [
    "# Text concatenation\n",
    "def create_product_text(row):\n",
    "    \"\"\"Concatenate all text columns into one description\"\"\"\n",
    "    text_parts = []\n",
    "    \n",
    "    # product name\n",
    "    if pd.notna(row['Product Name']):\n",
    "        text_parts.append(f\"This product is {row['Product Name']}\")\n",
    "    \n",
    "    # category\n",
    "    if pd.notna(row['Category']):\n",
    "        text_parts.append(f\"It falls under the category of {row['Category']}\")\n",
    "    \n",
    "    # price\n",
    "    if pd.notna(row['Selling Price']):\n",
    "        text_parts.append(f\"The price is {row['Selling Price']}\")\n",
    "    \n",
    "    # model number\n",
    "    if pd.notna(row['Model Number']):\n",
    "        text_parts.append(f\"The model number is {row['Model Number']}\")\n",
    "    \n",
    "    # main description\n",
    "    if pd.notna(row['About Product']):\n",
    "        text_parts.append(f\"Product description: {row['About Product']}\")\n",
    "    \n",
    "    # technical details\n",
    "    if pd.notna(row['Technical Details']):\n",
    "        text_parts.append(f\"Technical specifications: {row['Technical Details']}\")\n",
    "    \n",
    "    # shipping info\n",
    "    if pd.notna(row['Shipping Weight']):\n",
    "        text_parts.append(f\"Shipping weight is {row['Shipping Weight']}\")\n",
    "    \n",
    "    # dimensions\n",
    "    if pd.notna(row['Product Dimensions']):\n",
    "        text_parts.append(f\"Product dimensions are {row['Product Dimensions']}\")\n",
    "    \n",
    "    # seller info\n",
    "    if pd.notna(row['Is Amazon Seller']):\n",
    "        seller_text = \"The product is sold by Amazon\" if str(row['Is Amazon Seller']).lower() == 'true' else \"The product is not sold by Amazon\"\n",
    "        text_parts.append(f\"This item is {seller_text}\")\n",
    "    \n",
    "    # combine into one text\n",
    "    return \". \".join(text_parts) + \".\"\n",
    "\n",
    "# Test it\n",
    "sample_text = create_product_text(exploded_df.iloc[0])\n",
    "print(\"=\"*60)\n",
    "print(\"TESTING...\")\n",
    "print(\"=\"*60)\n",
    "print(sample_text)\n",
    "\n",
    "# create new column\n",
    "print(\"\\nCreating new column...\")\n",
    "exploded_df['text_to_embed'] = exploded_df.apply(create_product_text,axis=1)\n",
    "print(\"...new column created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac61382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Deleting repeated text columns (result of 'explosion')\n",
      "------------------------------------------------------------\n",
      "Using 10002 unique products for text embedding\n"
     ]
    }
   ],
   "source": [
    "# FUNCTION SETUP\n",
    "def get_text_embedding(text):\n",
    "    inputs = processor(text=[text], return_tensors=\"pt\", padding=True, truncation=True, max_length=77)\n",
    "    with torch.no_grad():\n",
    "        embedding = model.get_text_features(**inputs)\n",
    "    return embedding.numpy()[0]\n",
    "\n",
    "def create_overlapping_chunks(text, chunk_size=77, overlap=15):\n",
    "    \"\"\"Split text into overlapping chunks of specified token size\"\"\"\n",
    "    try:\n",
    "        # Tokenize the full text\n",
    "        inputs = processor(text=[text], return_tensors=\"pt\", padding=True)\n",
    "        tokens = inputs['input_ids'][0]  # Get token IDs\n",
    "        \n",
    "        chunks = []\n",
    "        start = 0\n",
    "        \n",
    "        while start < len(tokens):\n",
    "            # Get chunk of tokens\n",
    "            end = min(start + chunk_size, len(tokens))\n",
    "            chunk_tokens = tokens[start:end]\n",
    "            \n",
    "            # Decode back to text\n",
    "            chunk_text = processor.tokenizer.decode(chunk_tokens, skip_special_tokens=True)\n",
    "            chunks.append(chunk_text)\n",
    "            \n",
    "            # Move start position with overlap\n",
    "            if end >= len(tokens):\n",
    "                break\n",
    "            start = end - overlap\n",
    "        \n",
    "        return chunks\n",
    "    except Exception as e:\n",
    "        print(f\"Error chunking text: {e}\")\n",
    "        return [text[:500]]  # Fallback to first 500 chars\n",
    "\n",
    "def get_text_embedding_from_chunk(text_chunk, uniq_id, chunk_number):\n",
    "    \"\"\"Get CLIP text embedding + metadata\"\"\"\n",
    "    try:\n",
    "        if text_chunk.strip():\n",
    "            print(f\"Processing text chunk {chunk_number} for {uniq_id}\")\n",
    "            embedding = get_text_embedding(text_chunk)\n",
    "            \n",
    "            metadata = {\n",
    "                \"uniq_id\": str(uniq_id),\n",
    "                \"type\": \"text\",\n",
    "                \"chunk\": chunk_number\n",
    "            }\n",
    "            return embedding, metadata\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# BATCH PROCESSING SETUP\n",
    "BATCH_SIZE = 100\n",
    "embeddings_to_store = []\n",
    "metadatas_to_store = []\n",
    "ids_to_store = []\n",
    "\n",
    "\n",
    "# Get unique products only for text embedding\n",
    "print(\"-\"*60)\n",
    "print(\"Deleting repeated text columns (result of 'explosion')\")\n",
    "print(\"-\"*60)\n",
    "unique_df = exploded_df.drop_duplicates(subset=['Uniq Id'])\n",
    "print(f\"Using {len(unique_df)} unique products for text embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d7b13a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (340 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TESTING TEXT EMBEDDING\n",
      "============================================================\n",
      "------------------------------------------------------------\n",
      "EMBEDDING\n",
      "------------------------------------------------------------\n",
      "Processing text chunk 1 for 4c69b61db1fc16e7013b43fc926e502d\n",
      "Processing text chunk 2 for 4c69b61db1fc16e7013b43fc926e502d\n",
      "Processing text chunk 3 for 4c69b61db1fc16e7013b43fc926e502d\n",
      "Processing text chunk 4 for 4c69b61db1fc16e7013b43fc926e502d\n",
      "Processing text chunk 5 for 4c69b61db1fc16e7013b43fc926e502d\n",
      "Processing text chunk 6 for 4c69b61db1fc16e7013b43fc926e502d\n",
      "Processing text chunk 1 for 66d49bbed043f5be260fa9f7fbff5957\n",
      "Processing text chunk 2 for 66d49bbed043f5be260fa9f7fbff5957\n",
      "Processing text chunk 3 for 66d49bbed043f5be260fa9f7fbff5957\n",
      "Processing text chunk 4 for 66d49bbed043f5be260fa9f7fbff5957\n",
      "Processing text chunk 5 for 66d49bbed043f5be260fa9f7fbff5957\n",
      "Processing text chunk 6 for 66d49bbed043f5be260fa9f7fbff5957\n",
      "Processing text chunk 7 for 66d49bbed043f5be260fa9f7fbff5957\n",
      "Processing text chunk 8 for 66d49bbed043f5be260fa9f7fbff5957\n",
      "Processing text chunk 1 for 2c55cae269aebf53838484b0d7dd931a\n",
      "Processing text chunk 2 for 2c55cae269aebf53838484b0d7dd931a\n",
      "Processing text chunk 3 for 2c55cae269aebf53838484b0d7dd931a\n",
      "Processing text chunk 4 for 2c55cae269aebf53838484b0d7dd931a\n",
      "Processing text chunk 5 for 2c55cae269aebf53838484b0d7dd931a\n",
      "Processing text chunk 6 for 2c55cae269aebf53838484b0d7dd931a\n",
      "Processing text chunk 7 for 2c55cae269aebf53838484b0d7dd931a\n",
      "Processing text chunk 8 for 2c55cae269aebf53838484b0d7dd931a\n",
      "Stored final batch of 22 text embeddings\n",
      "\n",
      "------------------------------------------------------------\n",
      "Checking results\n",
      "------------------------------------------------------------\n",
      "\n",
      "Total embeddings: 26\n",
      "Text embeddings: 22\n",
      "Image embeddings: 4\n",
      "Products with text embeddings: 3\n",
      "Average chunks per product: 7.3\n",
      "Max chunks for one product: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TESTING TEXT EMBEDDING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_df = unique_df.head(3)\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(\"EMBEDDING\")\n",
    "print(\"-\"*60)\n",
    "for i in range(len(test_df)):\n",
    "    row = test_df.iloc[i]\n",
    "    \n",
    "    if pd.notna(row['Uniq Id']) and pd.notna(row['text_to_embed']):\n",
    "        uniq_id = row['Uniq Id']\n",
    "        full_text = str(row['text_to_embed'])\n",
    "        \n",
    "        # Get chunks for this product\n",
    "        chunks = create_overlapping_chunks(full_text)\n",
    "        \n",
    "        # Process each chunk\n",
    "        for chunk_num, text_chunk in enumerate(chunks, 1):\n",
    "            \n",
    "            # Create unique ChromaDB ID for each chunk\n",
    "            unique_chroma_id = f\"text_{uniq_id}_{chunk_num}\"\n",
    "\n",
    "            # Skip if chunk was already embedded\n",
    "            try:\n",
    "                existing = collection.get(ids=[unique_chroma_id])\n",
    "                if existing['ids']: \n",
    "                    print(f\"Skipping {unique_chroma_id} - already exists\")\n",
    "                    continue\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Get embedding and metadata\n",
    "            result = get_text_embedding_from_chunk(text_chunk, uniq_id, chunk_num)\n",
    "            if result is not None:\n",
    "                embedding, metadata = result\n",
    "                if embedding is not None:\n",
    "                    embeddings_to_store.append(embedding.tolist())\n",
    "                    metadatas_to_store.append(metadata)\n",
    "                    ids_to_store.append(unique_chroma_id)\n",
    "            \n",
    "            # Store every BATCH_SIZE embeddings\n",
    "            if len(embeddings_to_store) >= BATCH_SIZE:\n",
    "                collection.add(embeddings=embeddings_to_store, metadatas=metadatas_to_store, ids=ids_to_store)\n",
    "                print(f\"Stored batch of {len(embeddings_to_store)} text embeddings\")\n",
    "                # Clear lists for next batch\n",
    "                embeddings_to_store = []\n",
    "                metadatas_to_store = []\n",
    "                ids_to_store = []\n",
    "\n",
    "# Store final batch\n",
    "if embeddings_to_store:\n",
    "    collection.add(embeddings=embeddings_to_store, metadatas=metadatas_to_store, ids=ids_to_store)\n",
    "    print(f\"Stored final batch of {len(embeddings_to_store)} text embeddings\")\n",
    "\n",
    "print()\n",
    "print(\"-\"*60)\n",
    "print(\"Checking results\")\n",
    "print(\"-\"*60)\n",
    "all_data = collection.get()\n",
    "print(f\"\\nTotal embeddings: {len(all_data['ids'])}\")\n",
    "\n",
    "# Count text vs image embeddings\n",
    "text_embeddings = [id for id in all_data['ids'] if id.startswith('text_')]\n",
    "image_embeddings = [id for id in all_data['ids'] if id.startswith('img_')]\n",
    "print(f\"Text embeddings: {len(text_embeddings)}\")\n",
    "print(f\"Image embeddings: {len(image_embeddings)}\")\n",
    "\n",
    "# Check text chunks per product\n",
    "text_metadata = [meta for meta in all_data['metadatas'] if meta['type'] == 'text']\n",
    "text_uniq_ids = [meta['uniq_id'] for meta in text_metadata]\n",
    "unique_text_uniq_ids = set(text_uniq_ids)\n",
    "print(f\"Products with text embeddings: {len(unique_text_uniq_ids)}\")\n",
    "\n",
    "# Show chunks per product\n",
    "from collections import Counter\n",
    "chunks_per_product = Counter(text_uniq_ids)\n",
    "print(f\"Average chunks per product: {len(text_uniq_ids) / len(unique_text_uniq_ids):.1f}\")\n",
    "print(f\"Max chunks for one product: {max(chunks_per_product.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "231ff647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL VECTOR STORE VERIFICATION\n",
      "============================================================\n",
      "Collection name: amazon_products_exploded\n",
      "Total embeddings: 26\n",
      "\n",
      "Image embeddings: 4\n",
      "Text embeddings: 22\n",
      "\n",
      "Products with text embeddings: 3\n",
      "Products with image embeddings: 1\n",
      "Products with BOTH text and images: 1\n",
      "\n",
      "Sample image IDs: ['img_4c69b61db1fc16e7013b43fc926e502d_0', 'img_4c69b61db1fc16e7013b43fc926e502d_1', 'img_4c69b61db1fc16e7013b43fc926e502d_2']\n",
      "Sample text IDs: ['text_4c69b61db1fc16e7013b43fc926e502d_1', 'text_4c69b61db1fc16e7013b43fc926e502d_2', 'text_4c69b61db1fc16e7013b43fc926e502d_3']\n",
      "\n",
      "Search test - found types: {'text'}\n",
      "Both text and image embeddings are searchable!\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# FINAL VERIFICATION CHECK\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL VECTOR STORE VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check collection details\n",
    "print(f\"Collection name: {collection.name}\")\n",
    "print(f\"Total embeddings: {collection.count()}\")\n",
    "\n",
    "# Get all data\n",
    "all_data = collection.get()\n",
    "\n",
    "# Count by type\n",
    "text_embeddings = [id for id in all_data['ids'] if id.startswith('text_')]\n",
    "image_embeddings = [id for id in all_data['ids'] if id.startswith('img_')]\n",
    "\n",
    "print(f\"\\nImage embeddings: {len(image_embeddings)}\")\n",
    "print(f\"Text embeddings: {len(text_embeddings)}\")\n",
    "\n",
    "# Check they have the same uniq_ids (products)\n",
    "text_uniq_ids = set([meta['uniq_id'] for meta in all_data['metadatas'] if meta['type'] == 'text'])\n",
    "image_uniq_ids = set([meta['uniq_id'] for meta in all_data['metadatas'] if meta['type'] == 'image'])\n",
    "\n",
    "print(f\"\\nProducts with text embeddings: {len(text_uniq_ids)}\")\n",
    "print(f\"Products with image embeddings: {len(image_uniq_ids)}\")\n",
    "print(f\"Products with BOTH text and images: {len(text_uniq_ids & image_uniq_ids)}\")\n",
    "\n",
    "# Sample IDs to verify format\n",
    "print(f\"\\nSample image IDs: {image_embeddings[:3] if image_embeddings else 'None'}\")\n",
    "print(f\"Sample text IDs: {text_embeddings[:3] if text_embeddings else 'None'}\")\n",
    "\n",
    "# Quick search test to make sure both work\n",
    "try:\n",
    "    query_text = \"longboard skateboard\"\n",
    "    query_embedding = get_text_embedding(query_text)  # 512 dims\n",
    "\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding.tolist()],  # 512 dims\n",
    "        n_results=5\n",
    "    )\n",
    "\n",
    "    result_types = [meta['type'] for meta in results['metadatas'][0]]\n",
    "    print(f\"\\nSearch test - found types: {set(result_types)}\")\n",
    "    print(\"Both text and image embeddings are searchable!\")\n",
    "except Exception as e:\n",
    "    print(f\"Search test failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aacc48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9376c5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8de79",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"=\"*60)\n",
    "# print(\"FULL DATASET TEXT EMBEDDING\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# test_df = unique_df.head(5)\n",
    "\n",
    "# print(\"-\"*60)\n",
    "# print(\"EMBEDDING\")\n",
    "# print(\"-\"*60)\n",
    "# for i in range(len(test_df)):\n",
    "#     row = test_df.iloc[i]\n",
    "    \n",
    "#     if pd.notna(row['Uniq Id']) and pd.notna(row['text_to_embed']):\n",
    "#         uniq_id = row['Uniq Id']\n",
    "#         full_text = str(row['text_to_embed'])\n",
    "        \n",
    "#         # Get chunks for this product\n",
    "#         chunks = create_overlapping_chunks(full_text)\n",
    "        \n",
    "#         # Process each chunk\n",
    "#         for chunk_num, text_chunk in enumerate(chunks, 1):\n",
    "            \n",
    "#             # Create unique ChromaDB ID for each chunk\n",
    "#             unique_chroma_id = f\"text_{uniq_id}_{chunk_num}\"\n",
    "\n",
    "#             # Skip if chunk was already embedded\n",
    "#             try:\n",
    "#                 existing = collection.get(ids=[unique_chroma_id])\n",
    "#                 if existing['ids']: \n",
    "#                     print(f\"Skipping {unique_chroma_id} - already exists\")\n",
    "#                     continue\n",
    "#             except:\n",
    "#                 pass\n",
    "            \n",
    "#             # Get embedding and metadata\n",
    "#             result = get_text_embedding_from_chunk(text_chunk, uniq_id, chunk_num)\n",
    "#             if result is not None:\n",
    "#                 embedding, metadata = result\n",
    "#                 if embedding is not None:\n",
    "#                     embeddings_to_store.append(embedding.tolist())\n",
    "#                     metadatas_to_store.append(metadata)\n",
    "#                     ids_to_store.append(unique_chroma_id)\n",
    "            \n",
    "#             # Store every BATCH_SIZE embeddings\n",
    "#             if len(embeddings_to_store) >= BATCH_SIZE:\n",
    "#                 collection.add(embeddings=embeddings_to_store, metadatas=metadatas_to_store, ids=ids_to_store)\n",
    "#                 print(f\"Stored batch of {len(embeddings_to_store)} text embeddings\")\n",
    "#                 # Clear lists for next batch\n",
    "#                 embeddings_to_store = []\n",
    "#                 metadatas_to_store = []\n",
    "#                 ids_to_store = []\n",
    "\n",
    "# # Store final batch\n",
    "# if embeddings_to_store:\n",
    "#     collection.add(embeddings=embeddings_to_store, metadatas=metadatas_to_store, ids=ids_to_store)\n",
    "#     print(f\"Stored final batch of {len(embeddings_to_store)} text embeddings\")\n",
    "\n",
    "# print()\n",
    "# print(\"-\"*60)\n",
    "# print(\"Checking results\")\n",
    "# print(\"-\"*60)\n",
    "# all_data = collection.get()\n",
    "# print(f\"\\nTotal embeddings: {len(all_data['ids'])}\")\n",
    "\n",
    "# # Count text vs image embeddings\n",
    "# text_embeddings = [id for id in all_data['ids'] if id.startswith('text_')]\n",
    "# image_embeddings = [id for id in all_data['ids'] if id.startswith('img_')]\n",
    "# print(f\"Text embeddings: {len(text_embeddings)}\")\n",
    "# print(f\"Image embeddings: {len(image_embeddings)}\")\n",
    "\n",
    "# # Check text chunks per product\n",
    "# text_metadata = [meta for meta in all_data['metadatas'] if meta['type'] == 'text']\n",
    "# text_uniq_ids = [meta['uniq_id'] for meta in text_metadata]\n",
    "# unique_text_uniq_ids = set(text_uniq_ids)\n",
    "# print(f\"Products with text embeddings: {len(unique_text_uniq_ids)}\")\n",
    "\n",
    "# # Show chunks per product\n",
    "# from collections import Counter\n",
    "# chunks_per_product = Counter(text_uniq_ids)\n",
    "# print(f\"Average chunks per product: {len(text_uniq_ids) / len(unique_text_uniq_ids):.1f}\")\n",
    "# print(f\"Max chunks for one product: {max(chunks_per_product.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9d0db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ba059c3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eaf209f",
   "metadata": {},
   "source": [
    "# OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1cd368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEAVIER METADATA\n",
    "# def get_image_embedding_from_url(url_string, product_row):\n",
    "#     \"\"\"Download image from URL and get CLIP embedding + metadata - no saving on local\"\"\"\n",
    "#     try:\n",
    "#         uniq_id = product_row['Uniq Id']\n",
    "\n",
    "#         # split by | and get all urls\n",
    "#         urls = url_string.split('|')\n",
    "\n",
    "#         # find first URL that is not a transparent pixel\n",
    "#         for url in urls:\n",
    "#             url = url.strip()\n",
    "#             if 'transparent-pixel.jpg' not in url:\n",
    "#                 print(f\"Trying: {url}\")\n",
    "\n",
    "#                 # download to memory (not disk)\n",
    "#                 response = requests.get(url)\n",
    "#                 if response.status_code == 200:\n",
    "#                     # get image\n",
    "#                     image = Image.open(BytesIO(response.content))\n",
    "\n",
    "#                     # get CLIP embedding\n",
    "#                     embedding = get_image_embedding(image) # This just returns a numpy array - no metadata! I NEED TO ADD METADATA\n",
    "\n",
    "#                     # Create Metadata\n",
    "\n",
    "#                     # # very heavy metadata option\n",
    "#                     # metadata = {\n",
    "#                     #     \"uniq_id\": str(uniq_id),\n",
    "#                     #     \"product_name\": product_row['Product Name'],\n",
    "#                     #     \"category\": product_row['Category'],\n",
    "#                     #     \"price\": str(product_row['Selling Price']),\n",
    "#                     #     \"type\": \"image\", # Important: identifies this as image embedding. It is \"text\" for text\n",
    "#                     #     \"source_url\": url\n",
    "#                     # }\n",
    "\n",
    "#                     print(f\"Got embedding for {uniq_id}\")\n",
    "#                     return embedding, metadata\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"ERROR: {e}\")\n",
    "#         return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73cb152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
